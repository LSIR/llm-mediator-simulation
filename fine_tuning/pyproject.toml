[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "olmo_reddit_finetuning"
version = "0.0.4"
description = "Fine-tuning OLMo-2 on Reddit ChangeMyView data"
requires-python = ">=3.12"
license = "MIT"
dependencies = [
    "torch>=2.1.0",
    "transformers>=4.38.0",
    "datasets>=2.16.0",
    "peft>=0.8.0",
    "accelerate>=0.27.0",
    "bitsandbytes>=0.42.0",
    "wandb>=0.16.0",
    "tqdm>=4.66.0",
    "jsonlines>=4.0.0",
    "python-dotenv",
    "hydra-core",
    "trl",
]

[tool.hatch.envs.default]
type = "virtual"
path = ".venv"
python = "3.12"


[tool.hatch.envs.default.scripts]
sft-lora = "accelerate launch train_olmo_reddit.py {args}"

[tool.hatch.envs.runai]
extra-dependencies = ["pip-tools"]
description = """
Utilities to run a ML project on RunAI
"""

[tool.hatch.envs.runai.scripts]
docker-image-name = "echo {env:DOCKER_IMAGE_NAME}"
build-local = ["""
    docker build -t {env:DOCKER_IMAGE_NAME}:$(hatch version) \
    --target local .
    """]
train-local = """
    OUTPUT_PATH=/fine-tuning/output && \
    docker run --gpus all \
    -v /mnt/nlp4sd/hugging_face_cache/laugier/hub:/root/.cache/huggingface/hub \
    -v /mnt/datastore/laugier/olmo2-cga-cmv/sft:$OUTPUT_PATH \
    -v $(pwd)/.env:/fine-tuning/.env \
    {env:DOCKER_IMAGE_NAME}:$(hatch version) accelerate launch {env:TRAINING_SCRIPT} training.output_path=$OUTPUT_PATH {args}
"""
build = ["""
    docker build -t {env:DOCKER_IMAGE_NAME}:$(hatch version) \
    --target runai \
    --build-arg LDAP_GROUPNAME=lsir \
    --build-arg LDAP_GID=11255 \
    --build-arg LDAP_USERNAME=laugier \
    --build-arg LDAP_UID=269408 ."""]
push = "docker push {env:DOCKER_IMAGE_NAME}:$(hatch version)"
read-env = "python -c \"from dotenv import load_dotenv; import os; load_dotenv(); print(os.getenv('WANDB_API_KEY'))\""
submit = """
    runai submit {env:RUNAI_JOB_NAME} \
    --image {env:DOCKER_IMAGE_NAME}:$(hatch version) \
    --existing-pvc claimname=lsir-scratch,path=/scratch \
    --existing-pvc claimname=home,path=/home/laugier \
    --gpu {env:N_GPUS} \
    --node-pools {env:NODE_POOL} \
    --environment WANDB_API_KEY=$(hatch run runai:read-env) \
    --environment CONFIG_PATH=/home/laugier/llm-mediator-simulation/fine_tuning/configs \
    --environment HF_HOME={env:HF_HOME} \
    """
train = """submit --large-shm --command -- accelerate launch \
--mixed_precision=bf16 \
--num_processes={env:N_GPUS} \
--num_machines=1 \
--dynamo_backend=inductor \
/home/laugier/llm-mediator-simulation/fine_tuning/{env:TRAINING_SCRIPT} \
training.output_path=/mnt/lsir/nlp4sd/laugier_rcp/olmo2-cga-cmv/sft \
data.path=/home/laugier/llm-mediator-simulation/data/reddit/cmv/cga_cmv_pairs_before_derailment.jsonl \
{args}"""
interactive = "submit --interactive -- sleep infinity"
bash = "runai bash {args}"
describe = "runai describe job {args}"
delete = "runai delete job {args}"
logs = "runai logs {args}"
jobs = "runai list jobs"
last-job-name = "runai list jobs | tail -n 1 | cut -d ' ' -f1"
describe-last-job = "runai describe job $(runai list jobs | tail -n 1 | cut -d ' ' -f1)"
bash-last-job = "runai bash $(runai list jobs | tail -n 1 | cut -d ' ' -f1)"
delete-last-job = "runai delete job $(runai list jobs | tail -n 1 | cut -d ' ' -f1)"
logs-last-job = "runai logs $(runai list jobs | tail -n 1 | cut -d ' ' -f1)"

[tool.hatch.envs.runai.env-vars]
DOCKER_IMAGE_NAME = "registry.rcp.epfl.ch/lsir/laugier/olmo-reddit-sft"
TRAINING_SCRIPT = "train_olmo_reddit.py"
RUNAI_JOB_NAME = "laugier-olmo-reddit-sft-$(date +\"%d%m%y-%H%M%S\")"
N_GPUS = "4"
NODE_POOL = "default"
HF_HOME = "/scratch/laugier/hugging_face_cache"


[tool.hatch.build.targets.wheel]
packages = ["."]
