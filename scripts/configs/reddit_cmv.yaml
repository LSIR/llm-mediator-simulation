defaults:
  - defaults
  - debate_config: DebateConfig1
  - summary_config: SummaryConfig1
  - _self_
#   - override hydra/hydra_logging: disabled # Comment to enable hydra saving
#   - override hydra/job_logging: disabled # Comment to enable hydra saving

# hydra: # Comment to enable hydra saving
#   output_subdir: null # Comment to enable hydra saving
#   run: # Comment to enable hydra saving
#     dir: . # Comment to enable hydra saving

# With Olmo2's tokenizer (cl100k_base), the following json backbone consumes 27 tokens:
# 
# {
#   "do_intervene": true,
#   "intervention_justification": "",
#   "text": ""
# }
# ```
# We want max 500 characters in the text, and, say max 100 characters in the justification.
# As 1 token ~= 4 chars in English https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
# We calculate: max_new_tokens = 500/4 + 100/4 + 27 = 177 rounded to 200

max_new_tokens: 100
json_debater_reponse: True

# submission_id: "3jyxn7" 
# comment_id: "cuteyi2"


submission_id: "3ko9vd" # OK
comment_id: "cuz35v2"

# submission_id: "3lqidx" # KO
# comment_id: "cv8gsnh" 

# submission_id: "3mhgci" # OK
# comment_id: "cveysuq"

# submission_id: "3oz6yk"
# comment_id: "cw1r1b3"

# submission_id: "3q2zo7"
# comment_id: "cwbmwc2"